<!DOCTYPE html>
<html lang="en">

<head>
  <meta charset="UTF-8" />
  <meta name="viewport" content="width=device-width, initial-scale=1.0" />
  <title>VLONS: Vision-and-Language On-device Navigation System</title>

  <style>
    body {
      font-family: -apple-system, BlinkMacSystemFont, "Segoe UI", Roboto,
        Helvetica, Arial, sans-serif;
      margin: 0;
      padding: 0;
      line-height: 1.6;
      background: #fafafa;
      color: #222;
    }

    .container {
      width: 90%;
      max-width: 900px;
      margin: auto;
      padding: 40px 0;
    }

    h1, h2, h3 {
      font-weight: 600;
    }

    .title {
      text-align: center;
      margin-bottom: 10px;
    }

    .authors {
      text-align: center;
      color: #555;
      margin-bottom: 20px;
    }

    a {
      color: #0056d6;
      text-decoration: none;
    }

    a:hover {
      text-decoration: underline;
    }

    pre {
      background: #f2f2f2;
      padding: 15px;
      overflow-x: auto;
      border-radius: 5px;
    }

    video, iframe {
      width: 100%;
      max-width: 800px;
      border-radius: 6px;
      margin: 20px 0;
    }

    .section {
      margin-top: 40px;
    }

    .pdf-button {
      display: inline-block;
      background: #0056d6;
      color: #fff;
      padding: 10px 18px;
      border-radius: 6px;
      margin: 15px 0;
    }

    .pdf-button:hover {
      background: #003e9e;
    }

    .footer {
      text-align: center;
      margin-top: 50px;
      padding: 20px 0;
      color: #888;
      font-size: 14px;
    }
  </style>
</head>

<body>
  <div class="container">

    <!-- Title -->
    <h1 class="title">VLONS: A Vision-and-Language On-device Navigation System with Multimodal Fusion and Modular Framework</h1>

    <!-- Authors -->
    <p class="authors">
      <em>Authors: Jianyang Shi, Haijun Zhang, Yuhan Zhang, Tin Lun Lam, Lin Zhang, Hu Huang, Yuan Gao</em>
    </p>

    <!-- PDF link -->
    <!-- <p style="text-align:center;">
      <a href="paper.pdf" target="_blank" class="pdf-button">ðŸ“„ Download Paper PDF</a>
    </p> -->

    <!-- Abstract -->
    <div class="section">
      <h2>Abstract</h2>
      <p>
        A fundamental challenge in embodied intelligence is developing vision-and-language navigation (VLN) systems
        that operate efficiently on resource-constrained devices while possessing plug-and-play generalization
        capabilities. Current approaches often struggle with edge-side inference, platform compatibility, and task
        extensibility.

        Inspired by the modular architecture of human cognition, we present VLONS (Vision-and-Language On-device
        Navigation System), which introduces a novel framework for edge-optimized multimodal fusion and inference that
        achieves precise semantic alignment while eliminating computational redundancies. Our key innovation lies in
        decoupling the navigation pipeline into hierarchical computational modules that can be fully deployed on-device
        while enabling the system to maintain state-of-the-art performance.

        This architecture demonstrates remarkable zero-shot generalization to both dynamic and region navigation tasks.
        Through extensive experimentation, we show that VLONS achieves an 11.5Ã— improvement in retrieval efficiency and
        a 1.46Ã— boost in navigation accuracy compared to existing methods on the edge side, while matching the accuracy
        of cloud-based deployment methods. Compared to the previous best cloud-based method based, inference latency has
        improved by a factor of 5.93. The systemâ€™s generalizability has been further validated through practical
        deployment across multiple robotic platforms, making it the first edge-side VLN to support heterogeneous robots
        and multi-task navigation.
      </p>
    </div>

    <!-- Video -->
    <div class="section">
      <h2>Static Target</h2>

      <!-- Placeholder for video after upload -->
      <video controls>
        <source src="demo/static/box.mp4" type="video/mp4">
        <!-- <source src="demo/static/plant.mp4" type="video/mp4">
        <source src="demo/static/trash@car.mp4" type="video/mp4">
        <source src="demo/static/tv.mp4" type="video/mp4"> -->
      </video>

      <video controls>
        <source src="https://gs--public.oss-cn-beijing.aliyuncs.com/demo/static/plant.mp4" type="video/mp4">
      </video>

      <video controls>
        <source src="https://gs--public.oss-cn-beijing.aliyuncs.com/demo/static/trash&car.mp4" type="video/mp4">
      </video>

      <video controls>
        <source src="https://gs--public.oss-cn-beijing.aliyuncs.com/demo/static/tv.mp4" type="video/mp4">
      </video>

      <h2>Dynamic Target</h2>

      <!-- Placeholder for video after upload -->
      <video controls>
        <source src="https://gs--public.oss-cn-beijing.aliyuncs.com/demo/dynamic/bucket.mov" type="video/mp4">
      </video>
      <video controls>
        <source src="https://gs--public.oss-cn-beijing.aliyuncs.com/demo/dynamic/man.mov" type="video/mp4">
      </video>
      <video controls>
        <source src="https://gs--public.oss-cn-beijing.aliyuncs.com/demo/dynamic/people.mp4" type="video/mp4">
      </video>

      <h2>Region Target</h2>

      <!-- Placeholder for video after upload -->
      <video controls>
        <source src="https://gs--public.oss-cn-beijing.aliyuncs.com/demo/region/corridor3.mp4" type="video/mp4">
        <!-- <source src="region/indoor1.mp4" type="video/mp4">
        <source src="region/indoor2.mp4" type="video/mp4">
        <source src="region/indoor3.mp4" type="video/mp4">
        <source src="region/outdoor.mp4" type="video/mp4"> -->
      </video>
      <video controls>
        <source src="https://gs--public.oss-cn-beijing.aliyuncs.com/demo/region/indoor1.mp4" type="video/mp4">
      </video>
      <video controls>
        <source src="https://gs--public.oss-cn-beijing.aliyuncs.com/demo/region/indoor2.mp4" type="video/mp4">
      </video>
      <video controls>
        <source src="https://gs--public.oss-cn-beijing.aliyuncs.com/demo/region/indoor3.mp4" type="video/mp4">
      </video>
      <video controls>
        <source src="https://gs--public.oss-cn-beijing.aliyuncs.com/demo/region/outdoor.mp4" type="video/mp4">
      </video>
      <!-- If using Bilibili/YouTube, replace video block with iframe -->
      <!--
      <iframe src="https://www.youtube.com/embed/XXXXXX" allowfullscreen></iframe>
      -->
    </div>

    <!-- Project Highlights -->
    <div class="section">
      <h2>Key Features of VLONS</h2>
      <ul>
        <li>Edge-optimized multimodal fusion pipeline</li>
        <li>Modular hierarchical computation inspired by human cognition</li>
        <li>Zero-shot generalization on dynamic & region navigation</li>
        <li>11.5Ã— retrieval efficiency improvement</li>
        <li>1.46Ã— boost in on-device navigation accuracy</li>
        <li>5.93Ã— faster inference compared to cloud-based models</li>
        <li>Supports heterogeneous robots and multi-task navigation</li>
      </ul>
    </div>

    <!-- BibTeX -->
    <div class="section">
      <h2>BibTeX</h2>
      <pre>
        @ARTICLE{11270935,
        author={Shi, Jianyang and Zhang, Haijun and Zhang, Yuhan and Lam, Tin Lun and Zhang, Lin and Huang, Hu and Gao, Yuan},
        journal={IEEE Transactions on Consumer Electronics}, 
        title={VLONS: A Vision-and-Language On-device Navigation System with Multimodal Fusion and Modular Framework}, 
        year={2025},
        volume={},
        number={},
        pages={1-1},
        keywords={Navigation;Robots;Semantics;Consumer electronics;Artificial intelligence;Cognition;Robot sensing systems;Computer architecture;Real-time systems;Accuracy;Vision-and-Language Navigation;Embodied AI;Heterogeneous Robots;Edge Intelligence},
        doi={10.1109/TCE.2025.3638139}}
      </pre>
    </div>

    <!-- Footer -->
    <div class="footer">
      VLONS Project Page 
    </div>
  </div>
</body>

</html>
